{
  "model_id": "llama-4-maverick",
  "local_path": "~/models/llama-4-maverick",
  "deployment_type": "vllm",
  "num_gpus": 4,
  "dtype": "auto",
  "max_model_len": null,
  "generation_params": {
    "max_tokens": 4096,
    "temperature": 0.7,
    "top_p": 0.9
  }
} 