{
  "model_id": "LLaMA/llama3-8B-Instruct",
  "deployment_type": "vllm",
  "num_gpus": 2,
  "dtype": "auto",
  "max_model_len": null,
  "generation_params": {
    "max_tokens": 512,
    "temperature": 0.7,
    "top_p": 0.9
  }
} 